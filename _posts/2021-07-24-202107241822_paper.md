---
layout: post
title: "Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation"
category: paper
changefreq : daily
priority : 1.0
comments : true
permalink : /:categories/:year/:month/:day/:title/
math_use : true
sitemap : false
---

H. -Y. Tseng, H. -V. Lee, J. -B. Huang, and M. -H. Yang, "Cross-domain few-shot classification via learned feature-wise transformation," ICLR, 2020

## Abstract

- Address the problem of few-shot classification under domain shifts for metric-based methods.
- Our core idea is to use feature-wise transformation layers for augmenting the image features using affine transforms <u>to simulate various feature distributions</u> under different domains in the training stage.

<br>

<br>

## Introduction

metric-based approaches consist of ...

- a feature encoder
  - the encoder first extracts the image features
- a metric function
  - takes the features of both labeled and unlabeled images as input
  - predicts the category of the query images

<br>

![image](https://user-images.githubusercontent.com/85778937/126869378-dcf21e99-10e3-4a23-95e7-473ee315820e.png)

→ **Problem formulation and motivation.**

Metric-based meta-learning models usually consist of a feature encoder **E** and metric function **M**. We aim to improve the generalization ability of the models training from seen domains to arbitrary unseen domains. The key observation is that the distributions of the image features extracted from tasks in the unseen domains are significantly different from those in the seen domains.

<br>

### Contributions

- Propose to use feature-wise transformation layers to simulate various image feature distributions extracted from the tasks in different domains. Our feature-wise transformation layers are method-agnostic and can be applied to various metric-based few-shot classification approaches for improving their generalization to unseen domains.
- **Develop a learning-to-learn method to optimize the hyper-parameters of the feature-wise transformation layers.** In contrast to the exhaustive parameter hand-tuning process, the proposed learning-to-learn algorithm is capable of finding the hyper-parameters for the feature-wise transformation layers to capture the variation of image feature distribution across various domains.
- Evaluate the performance of three metric-based few-shot classification models (including MatchingNet, RelationNet, and Graph Neural Networks) with extensive experiments under the domain generalization setting. We show that the proposed feature-wise transformation layers can effectively improve the generalization ability of metric-based models to unseen domains. We also demonstrate further performance improvement with our learning-to-learn scheme for learning the feature-wise transformation layers.

<br>

<br>

## Related Work

- Few-shot classification
  - aims to learn to recognize novel categories with a limited number of labeled examples in each class
  - three main classes of meta-learning approaches
    - recurrent-based frameworks
    - optimization-based schemes
    - metric-based methods
- Domain adaptation
  - aim to reduce the domain shift between the source and target domains
  - Most domain frameworks, however, target at adapting knowledge of the same category learned from the source to target domain and thus are less effective to handle novel category as in the few-shot classification scenarios.
- Domain generalization
  - aim at generalizing from a set of seen domains to the unseen domain without accessing instances from the unseen domain during the training stage
- Learning-based data augmentation
  - are designed to increase the diversity of data for the training process
- Conditional normalization
  - aims to modulate the activation via learned affine transformation conditioned on external data

<br>

<br>

## Methodology

### feature-wise transformation layer

![image](https://user-images.githubusercontent.com/85778937/126869966-a856c957-19eb-400b-8635-384933b7b6b4.png)

<br>

![image](https://user-images.githubusercontent.com/85778937/126870490-284b0887-5ff3-42c2-94ec-2a209f6d9116.png)

E에 feature-wise transformation layer를 삽입한다. 그렇게되면, training 단계에서 다양한 분포를 시뮬레이션해서 test 단계에서 일반화 기능을 개선할 수 있다. 

<br>

<br>

## Experimental results

### Datasets

- mini-ImageNet → seen domain
- CUB
- Cars
- Places
- Plantae

<br>

### Feature-wise transformation with manual parameter tuning

$$
\theta_{\gamma}, \theta_{\beta} = 0.3, 0.5
$$

add the proposed feature-wise transformation layers after the last batch normalization layer of all the residual blocks in the feature encoder E during the training stage

<br>

### Generalization from multiple domains

FT: pre-determined feature-wise transformation layers

LFT: those layers optimized with the proposed learning-to-learn algorithm

**LFT > FT**

이유 : the optimized feature-wise transformation layers can better capture the variation of feature distributions across different domains
