---
layout: post
title: "Feature Transformation Ensemble Model with Batch Spectral Regularization for Cross-Domain Few-Shot Classfication"
category: paper
changefreq : daily
priority : 1.0
comments : true
permalink : /:categories/:year/:month/:day/:title/
math_use : true
sitemap : false
---

X. Yue, Z. Zheng, S. Zhang, Y. Gao, T. Darrell, K. Keutzer, A. S. Vincentelli, "Prototypical cross-domain Self-supervised Learning for Few-shot Unsupervised Domain Adaptation," *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2021, pp. 13834-13844

<br>

CD-FSL challenge 1위 논문 → 73.94%

*솔직히 이해가 안된다.. 우선 정리는 해두지만, 다시 와서 볼 논문 1순위.*

*논문과 코드, 그림이 다 따로 노는 듯 하다. 아직 내 수준에서는 불가능..하다고 판단하여, 우선 그냥 그대로 올려놓는다.*

----

## Abstract

- use a batch spectral regularization term to suppress the singular values of the feature matrix during pre-training to improve the generalization ability
- further apply label propagation, entropy minimization and data augmentation to mitigate teh shortage of labeled data in target domains

<br>

<br>

## Introduction

source와 target gap이 클수록 → pre-training, fine-tuning 잘된다.

<br>

<br>

## Approach

![image](https://user-images.githubusercontent.com/85778937/126874198-83e85ec6-0b44-4f69-8b19-b4f697449894.png)



### Feature Transformation Ensemble Model

We build the ensemble model by increasing the diversity of the feature representation space while maintaining the usage of the entire training data for each prediction branch network.

### Batch Spectral Regularization

This regularization is applied for each branch network of the ensemble model separately in the same way.

![image](https://user-images.githubusercontent.com/85778937/126874446-c64824a7-79c3-4cfc-9b1a-45cfaf2c8086.png)

![image](https://user-images.githubusercontent.com/85778937/126874459-6f07d7df-eb1f-4349-b5bc-fbdabac5955d.png)

### Label Propagation

we propose to apply a label propagation (LP) step to exploit the semantic information of unlabeled test data in the extracted feature space and refine the original classification results

### Entropy Minimization

![image](https://user-images.githubusercontent.com/85778937/126874500-4a416245-692a-46a3-a3c7-333434115dca.png)

### Data Augmentation

We also exploit data augmentation (DA) strategy with several random operations to supplement the support set and make the models learn with more variations.
