---
layout: post
title: "Plug-and-Play Domain Adaptation for Cross-Subject EEG-based Emotion Recognition"
category: paper
changefreq : daily
priority : 1.0
comments : true
permalink : /:categories/:year/:month/:day/:title/
math_use : true
sitemap : false

---

L. –M. Zhao, X. Yan, and B. –L. Lu, “Plug-and-play domain adaptation for cross-subject EEG-based emotion recognition,” *Proceedings of the 35**th* *AAAI Conference on Artificial Intelligence*, 2021, pp. 1-8.

~~12월 31일 발표용 자료~~

<br>

## Goal
- Allowing everyone immediately use the proposed methodology without waiting while maintaining the recognition accuracy

<br>

## Motivation
- EEG data is highly subject dependent
  - Due to the structural and functional variability between subjects

<br>

## Materials and methods
- SEED dataset: 64-channel EEG data from 15 subjects
- Attention-based pooling
  - Attempting the attention mechanism to let the model automatically explore the critical channels and bands for emotion recognition
- LSTM-based encoder-decoder
  - Extracting the shared emotional components and private components of EEG representations separately
- Learning loss
  - $ L= L_(c_s)+〖αL〗_(c_p)+ βL_recon+ γL_difference+ δL_similarity $

<br>

![image](https://user-images.githubusercontent.com/85778937/150331612-302bcdf5-95aa-4637-8cb8-2628a01843a1.png)

<br>

![image](https://user-images.githubusercontent.com/85778937/150331564-0aa4bf2c-a21e-4562-ba8f-962a75a100d2.png)

<br>

## Results
- It shortens the calibration time while maintaining the recognition accuracy, which is of great practical significance
- Longer calibration time did not show significant performance improvement
- The beta and the gamma bands are much more activated than other three bands

<br>

![image](https://user-images.githubusercontent.com/85778937/150332182-52743ba1-4c6b-4e04-886f-21448545157b.png)

<br>

![image](https://user-images.githubusercontent.com/85778937/150332218-a008973b-6d6c-4745-80bf-7723da959962.png)
