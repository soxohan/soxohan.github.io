---
layout: post
title: "Offline EEG-Based Driver Drowsiness Estimation Using Enhanced Batch-Mode Active Learning (EBMAL) for Regression"
category: paper
changefreq : daily
priority : 1.0
comments : true
permalink : /:categories/:year/:month/:day/:title/
math_use : true
sitemap : false
---

D. Wu, V. J. Lawhern, S. Gordon, B. J. Lance, and C. –T. Lin, “Offline EEG-Based Driver Drowsiness Estimation Using Enhanced Batch-Mode Active Learning (EBMAL) for Regression,” *2016 IEEE* *Inernational* *Conference on Systems, Man, and Cybernetics (SMC)*, 2016, pp. 730-736.

~~베이지안 머신러닝의 과제를 위해 읽어본 active learning. regression이기는 한데 참고용. 발표용인 만큼 알고리즘에 집중했고, 결과는 빼고 기록한다.~~

좋았던 것은, QBC와 EMCM의 한계점을 설명을 잘했고, 이걸 해결하기 위한 방법이 직관적이고 이해하기 쉬웠던 것. (클러스터링 사용)

<br>

## Abstract

- The purpose is to minimize training set size by active learning (AL)
- Propose EBMAL algorithm to improve the reliability, representativeness and diversity of samples selected by a baseline QBC or EMCM approach
- The EMBAL approach has the best results of all methods in small number of repetitions of learning process

<br>

<br>

## Methods

- AL for Regression by Query-by-Committee (QBC)
  - P개의 regression model로 구성
- AL for Regression by Expected Model Change Maximization (EMCM)
  - P개의 regression model로 구성
- Limitations of the QBC and EMCM approach (3가지)
  - labeling된 data가 없으면 regression model 처음부터 구성을 할 수가 없다.
  - 선택한 sample들이 outlier일 수 있다.
    - 동일한 배치에서의 여러 선택된 표본은 서로 매우 가까울 수 있다.
      → 동일한 배치에서 sample의 다양성을 증가 시켜야 중복성을 감소시킬 수 있다.
- **EBMAL**
  - to select more reliable and representative seedling samples in the first batch, we perform k-means clustering on all unlabeled samples, where k equals the batch size
    각 군집의 표본수를 계산 → threshold보다 크지 않은 군집이 있는지 확인. (outlier일 확률이 많다.)
    이렇게 outlier일 가능성이 있다고 판단되면, 선택에서 제외. 그리고 모두가 threshold를 넘길 때까지 계속 반복.
    그 후, closest to its centroid and select it for labeling
  - to prevent potential outliers from being selected, we record all such samples from the initialization step and restrain them from consideration in all future iterations
    기록해놓고 outlier는 다 쳐내기
  - pre-select the top 2k samples using the baseline AL approach, and then perform k-means clustering on them, where k again equals the batch size
    2k개를 가지고 클러스터링해서, 동일한 배치에서 선택한 표본이 서로 잘 분리되도록 해

<br>

![image](https://user-images.githubusercontent.com/85778937/138501276-c808f2d0-33d3-49f9-9028-ec321bebac9d.png)
