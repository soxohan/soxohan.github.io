---
layout: post
title: "Code-Synthetic dataset"
category: my_progress
changefreq : daily
priority : 1.0
comments : true
permalink : /:categories/:year/:month/:day/:title/
math_use : true
sitemap : false

---

~~일찍 자고 싶다. 게으른 사람은 바로 저였어요~~

🗓️ 2023.02.26

오늘의 목표는 synthetic dataset을 만들어서 어디서 나의 연구가 잘못되었는지를 찾고자 하였다.

✨ 만약, 성능이 안나오면, 나의 score가 잘못된 것이라는 판단!

✨성능이 잘 나오면, 나의 사용 데이터들이 이상한 거니까 전처리에 집중할 것이라는 판단!!



### 만들어볼까!!

synthetic dataset을 만드는 것에 있어서 2가지의 생각이었다.

🎨 우선 정말정말 뚜렷하게 만들어보자. 누가봐도 <u>너는 anomaly!!!</u>라고 할 수 있을 정도의 데이터. 

🎨 그 다음으로는 MSCRED 논문의 synthetic data를 사용해보고 싶었다. csv를 [github](https://github.com/7fantasysz/MSCRED/tree/master/data)에서 다운받을 수 있었거든.. 심지어 데이터도 구경다했음..

colab에서 구경해보고싶다면, 다음과 같은 코드를 쳐보면 된다!

```python
!git clone https://github.com/7fantasysz/MSCRED.git
import pandas as pd
read_csv = pd.read_csv("/content/MSCRED/data/synthetic_data_with_anomaly-s-1.csv", header=None)
```

그런데 이 데이터는 30 * 20000 데이터다. 그러니까 시간은 30개고, feature가 20000개.. 근데 만든 과정은 굉장히 정성을 담았고, 센서데이터를 고려한 데이터라 슬쩍 이용해 볼 만하다고 생각했었다.

<br>

---

### 그래서 1차 계획을 실행해볼까!!

간단했다. 

train data는 100000개, test data는 10000개. anomaly 비율은 0.02로 설정해서 만들었다.

정상 분포는 정규분포 0, 0.08을 따르도록 했고, anomaly는 정규분포 0.5, 0.1을 따르도록 했다.

그래서 test data의 분포를 그려보면 다음과 같다.

![image](https://user-images.githubusercontent.com/85778937/221371772-a8d8677f-30ef-4092-a229-482f233d249c.png)

~~누가봐도 anomaly네!!!~~



시계열 순으로도 한 번 확인해볼까!!

![image](https://user-images.githubusercontent.com/85778937/221371817-fdccf410-5644-4506-994e-6ff41c56343e.png)

~~음 아주 완벽해.. 이정도면 구분될거야...~~



그 후에, 우리의 만만한 AutoEncoder(AE)를 돌려보았고, 결과는 아주 처참했다. 대체 무슨 일이지..?

> confusion matrix
> [[  0  0]
>  [1891 100]]
> f1 0.04782400765184122 / precision 0.5 / recall 0.025113008538422903

~~오 마이갓.. 예전에 누군가 나에게, 성능이 아주 개판이면 살짝만 고치면 반대의 성능이 나올 수 있다고 했었는데,, 그럼 잘 고치면 95%?!~~ 



그래도 성능이 아주 안좋게 나옴으로써, 고칠 여지가 보인다는 희망을 보았다!!! :-)

우선은 오늘 여기까지.. 고치고 오게따!!😙
