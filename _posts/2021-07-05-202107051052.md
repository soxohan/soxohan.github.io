---
layout: post
title: "A broader study of cross-domain few-shot learning"
category: paper
changefreq : daily
priority : 1.0
comments : true
permalink : /:categories/:year/:month/:day/:title/
math_use : true
sitemap : false
---

Y. Guo, N. C. Codella, L. Karlinsky, J. V. Codella, J. R. Smith, K. Saenko, T. Rosing, and R. Feris, "A broader study of cross-domain few-shot learning," *ECCV*, 2020, pp. 124-141

----

## Abstract

Propose the Broader Study of Cross-Domain Few-Shot Learning (BSCD-FSL)

→ consisting of image data from a diverse assortment of image acquisition methods

<br>

The results demonstrate that **state-of-art meta-learning methods are surprisingly outperformed by earlier meta-learning approaches**, and all meta-learning methods underperform in relation to simple fine-tuning by 12.8% average accuracy. In some cases, meta-learning even underperforms networks with random weights. Performance gains previously observed with methods specialized for cross-domain few-shot learning vanish in this more challenging benchmark. Finally, accuracy of all methods tend to correlate with dataset similarity to natural images, verifying the value of the benchmark to better represent the diversity of data seen in practice and guiding future research.

<https://github.com/IBM/cdfsl-benchmark>



## Introduction

![image](https://user-images.githubusercontent.com/85778937/125221942-051b9480-e304-11eb-8815-c28a6a01e1f9.png)

Recent work : **meta-learning based few-shot learning algorithms underperform** compared to traditional pre-training and fine-tining **when there exists a large shift between base and novel class domains**.

Benchmarks for coventional few-shot learning : have built cross-domain evaluation benchmarks that are **limited to natural images**

To fill this gap, propose the Broader Study of Cross-Domain Few-Shot Learning (BSCD-FSL) benchmark, which covers a spectrum of image types with varying levels of **similarity** to natural images.

<br>

### contributions

- We establish a new Broader Study of Cross-Domain Few-Shot Learning (BSCDFSL) benchmark, consisting of images from a diversity of image types with varying dissimilarity to natural images, according to 1) perspective distortion, 2) the semantic content, and 3) color depth.
- Under these conditions, we extensively evaluate the performance of current meta learning methods, including methods specifically tailored for cross-domain few-shot learning, as well as variants of fine-tuning.
- The results demonstrate that state-of-art meta-learning methods are outperformed by older meta-learning approaches, and all meta-learning methods underperform in relation to simple fine-tuning by 12.8% average accuracy. In some cases, metalearning underperforms even networks with random weights.
- Results also show that accuracy gains for cross-domain few-shot learning methods are lost in this new challenging benchmark.
- Finally, we find that accuracy of all methods correlate with the proposed measure of data similarity to natural images, verifying the diversity of the problem representation, and the value of the benchmark towards future research.

<br>

## Related Work

### Few-shot learning

**Meta-learning** methods aim to learn models that can be quickly adapted using a few examples

**Transfer learning** is based on the idea of <u>reusing features learned from the base classes for the novel classes</u>, and is conducted mainly by fine-tuning, which adjusts a pre-trained model from a source task to a target task.

Common to all few-shot learning methods is **the assumption that base classes and novel classes are from the same domain**.

<br>

### Domain Adaptation

aim at transferring knowledge from one or multiple source domains to a target domain with a different data distribution

however, consider the case that the training and test sets have the **same** classes

<br>

### Cross-domain Few-shot Learning

Base and novel classes are both drawn from different domains, and the class label sets are disjoint.



Common to all these prior works is that they <u>limit the cross-domain setting</u> to the realm of natural images, which still retain a high degree of visual similarity, and do not capture the broader spectrum of image types encountered in practice, such as industrial, aerial, and medical images, where cross-domain few-shot learning techniques are in high demand.

<br>

## Proposed Benchmark

includes data from CropDiseases, EuroSAT, ISIC2018, and ChestX datasets



<br>

Similarity is defined by 3 orthogonal criteria

- whether images contain perspective distortion
- the semantic content of images
- color depth

According to this criteria, the datasets demonstrate the following spectrum of image types

- CropDisease images are natural images, but are very specialized (similar to existing cross-domain few-shot setting, but specific to agriculture industry)
- EuroSAT images are less similar as they have lost perspective distortion, but are still color images of natural scenes
- ISIC2018 images are even less similar as they have lost perspective distortion and no longer represent natural scenes
- ChestX images are the most dissimilar as they have lost perspective distortion, do not represent natural scenes, and have lost 2 color channels

<br>

## Cross-Domain Few-Shot Learning Formulation

![image](https://user-images.githubusercontent.com/85778937/125227425-daced480-e30d-11eb-8c9a-2ece7a79ff84.png)

→ 여기서는 novel class의 label도 아는 것으로 보임.

(그래서 뒤에서, Adversarial Domain Adaptation with Reinforced Sample (ADA-RSS) Selection은 target domain에서 unlabelled data가 필요하므로 사용하지 않았다고 되어있음.)

<br>

## Evaluated Methods for Cross-Domain Few-Shot Learning

### 1. Meta-learning based methods

Meta learning aims at learning task-agnostic knowledge in order to efficiently learn on new tasks

#### Single Domain Methods

MatchingNet / +FWT

MAML

ProtoNet / +FWT

RelationNet / +FWT

MetaOpt

#### Cross-Domain Methods

Only few methods specifically tailored to learning in the condition of cross-domain few-shot learning have been previously explored, including **feaure-wise transform (FWT)** [58].

<u>FWT is a model agnostic approach that adds a feature-wise transform layer to pretrained models to learn scale and shift parameters from a collection of several dataset domains, or use parameters empirically determined from a single dataset domain.</u> Both approaches have been previously found to improve performance. Since our benchmark is focused on ImageNet as the single source domain, we focus on the single data domain approach. The method is studied in combination with all meta-learning algorithms described in the prior section.

<br>

### 2. Transfer learning based methods

#### Single Model Methods

we extensively evaluate the following commonly variants of single model fine-tuning

- *Fixed feature extractor (Fixed)* : adjusts all the pre-trained parameters on the new task with standard supervised learning
- *Fine-tuning all layers (Ft All)* : adjusts all the pre-trained parameters on the new task with standard supervised learning
- *Fine-tuning last-k (Ft Last-k)* : only the last k layers of the pre-trained model are optimized for the new task. 여기서는 k는 1, 2, 3을 고려
- *Transductive fine-tuning (Transductive Ft)* : in transductive fine-tuning, the statistics of the query images are used via batch normalization

In addition, we compare these single model transfer learning techniques against a baseline of an embedding formed by a randomly initialized network (termed Random) to contrast against a fixed feature vector that has no pre-training. All the variants of single model fine-tuning are based on linear classifier but differ in their approach to fine-tune the single model feature extractor.

- *Mean-centroid classifier*

- *Cosine-similarity based classifier*

#### Transfer from Multiple Pre-trained Models

![image](https://user-images.githubusercontent.com/85778937/125238556-59357180-e322-11eb-892f-e141d63030b4.png)

이 식은 다루기 힘들어서, 아래의 알고리즘을 대신 이용하였다.

two-stage greedy selection method , called Incremental Multi-model Selection, to iteratively find the best subset of layers for a given support S.

![image](https://user-images.githubusercontent.com/85778937/125238739-97cb2c00-e322-11eb-8393-f537965b8254.png)

