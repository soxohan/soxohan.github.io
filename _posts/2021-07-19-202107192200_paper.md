---
layout: post
title: "Few-shot learning via embedding adaptation with set-to-set functions"
category: paper
changefreq : daily
priority : 1.0
comments : true
permalink : /:categories/:year/:month/:day/:title/
math_use : true
sitemap : false
---

H. -J. Ye, H. Hu, D. -C. Zhan, and F. Sha, "Few-shot learning via embedding adaptation with set-to-set functions," CVPR, 2020, pp. 8808-8817.

----

## Abstract

- propose a novel approach to adapt the instance embeddings to the target classification task with a <u>set-to-set function</u>, yielding embeddings that are task-specific and are discriminative
- Observed the Transformer is most effective

<br>

<br>

## Introduction

- Few-Shot Learning (FSL)
  - N-way K-Shot task
  - Important limitation
    - Assuming a common embedding space implies that the discovered knowledge - discriminative visual features - on the SEEN classes are equally effective for any classification tasks constructed for an arbitrary set of UNSEEN classes. (SEEN 클래스에서 발견된 knowledge가 분류 작업에 대해 동등하게 효과적이라고 가정)
  - Difficulty
    - A complex model is prone to overfitting with limited training data

<br>

![image](https://user-images.githubusercontent.com/85778937/126863604-e28d8697-741c-49d6-b6ea-e4602d66443b.png)

set-to-set function을 이용하면, class 구분이 더 잘 되는 것을 알 수 있다. (결과 그림도 됨)

<br>

**Propose to adapt the embedding for each FSL task**

![image](https://user-images.githubusercontent.com/85778937/126863661-6d24d5f2-cf18-4499-9a32-2cbed189a2d0.png)

<br>

<br>

## Learning Embedding for Task-agnostic FSL

- Investigate 4 implementations of the set-to-set transformations
  - Set-to-set function
    - A function mapping that takes all instances from the few-shot support set and outputs the set of adapted support instance embedding
    - BILSTM, DeepSepts, GCN, **Transformer**
    - 설명하면, set-to-set 함수는 permutation으로 input을 넣어도 하나의 output이 나오는 매핑 함수라고 이해했다. 그래서 기존 CNN으로 했을 때는, 픽셀이 하나가 뒤바뀌면 다른 필터가 되어 permutation invariant하다고 할 수 없었지만, 위 4개는 permutation-permutation하다고 할 수 있다. 그래서 4개를 이용해봤을 때, transformer가 가장 좋은 성능을 보였고, FEAT를 제안한다.
  - FEAT (Few-shot Embedding Adaptation w/ Transformer)

![image](https://user-images.githubusercontent.com/85778937/126863896-21c78a76-79e4-4abe-839e-05d8cb6e0c0c.png)

<br>

---

### Soft Nearest Neighbor

여기서 Soft Nearest Neighbor 연산은 다음과 같다.

N. Frosst, N. Papernot, and G. Hinton, “Analyzing and Improving Representations with the Soft Nearest Neighbor Loss,” PMLR, 2019, pp. 2012-2020.

![image](https://user-images.githubusercontent.com/85778937/126863978-3e742928-c810-43d0-b7f5-97d0eb679641.png)

<br>

이를 이용하면, 아래의 결과를 얻을 수 있다고 한다.

![image](https://user-images.githubusercontent.com/85778937/126863988-d4fc89e2-6e26-497a-b68a-07c205b514ff.png)

---

다시 돌아와서, 여기서 주장하는 알고리즘 및 식은 다음과 같다.

 ![image](https://user-images.githubusercontent.com/85778937/126864020-df20ed7a-f7b1-4aa6-b3ae-045c02233ff7.png)

가장 중요한 건 **permutation-invariant**하게 한다는 것!!!
