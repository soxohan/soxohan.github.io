---
layout: post
title: "SACA Net: Cybersickness Assessment of Individual Viewers for VR Content via Graph-based Symptom Relation Embedding"
category: paper
changefreq : daily
priority : 1.0
comments : true
permalink : /:categories/:year/:month/:day/:title/
math_use : true
sitemap : false

---

S. Lee, J. U. Kim, H. G. Kim, S. Kim, and Y. M. Ro, "SACA Net: Cybersickness Assessment of Individual Viewers for VR Content via Graph-based Symptom Relation Embedding," *European Conference on Computer Vision*, 2020, pp. 170-186

----

## Abstract

**개별 viewers의 cybersickness를 평가하기 위한 물리적 증상 수준을 정량화하는 novel symptom-aware cybersickness assessment network (SACA Net) 제안**

관련 증상 중, 보완 효과를 위해 증상의 관계 특성을 활용하도록 설계

3개의 main part로 구성

- a stimulus symptom context guider (part1)
- a physiological symptom context guider (part2)
- a symptom relation embedder

part1 + part 2 = extract symptom features from VR content and human physiology, respectively

part3 = refines the stimulus-reponse symptom features to effectively predict cybersickness by embedding relational characteristics with graph formulation

latent relations among symptoms은 제안된 네트워크에서 관계 가중치를 분석하여 해석가능

<br>

<br>

## Introduction

VR content는 많은 분야에서 주목을 받고있음! 그런데 VR content를 보는데에 있어서의 안전에 우려가 있음. → trigger cybersickness and physical symptoms

physical symptoms

- nausea
  - containing sweating, salivation, burping
- oculomotor (안구 운동의)
  - containing visual fatigue and eye strain
- disorientation 
  - containing fullness of the head, dizziness, and vertigo

<br>

> When viewers watch VR content, they can feel different cybersickness even for the same content stimulus.
>
> Each viewer can feel cybersickness differently with distinct symptoms in detail.
>
> It is necessary to quantify detailed cybersickness of individual viewers.

> Individuals in the same stimulus environment could experience different cybersickness.

<br>

the existence of relationships among physical symptoms for cybersickness → Considering the realtionships, **devise a relational symptom embedding framework** that **can exploit the relational information** among symptoms to assess cybersickness.

The relevant symptom features complement each other for effectively predicting symptom levels.

<br>

**USE..**

- **2 public 360-degree video datasets**

- **simulator sickness questionnaire (SSQ) scores and physiological signals**

<br>

### Contributions

- introduce a novel SACA Net that quantifies cybersickness of individuals with physical symptoms by combining content stimulus and physiological response. 
  First attempt to quantify cybersickness including symptoms of individuals for VR content.
- propose symptom relation embedding which makes it possible to effectively assess cybersickness of individuals with distinct symptoms. Furthermore, latent symptom relations are interpretable by analyzing relational weights in the proposed network.



<br>

<br>

## Related Work

The generative model is trained with normal videos containing non-exceptional motions.

하지만, generative model은 exceptional motion이 있는 비디오를 적절하게 reconstruct 하지 못함

<br>

<br>

## Related Work

<br>

<br>

## Proposed Method

3 part

- the stimulus symptom context guider
  - extracts the **symptom group features** that represent the context of sickness-inducing stimulus environment
- the physiological symptom guider
  - utilizes physiological signals being collected from humans while watching the VR content to extract **symptom features**
    VR 시청하는 동안 사람의 생리학적 신호를 활용하여 특징 추출
- the symptom relation embedder
  - based on the symptom group features and the symptom features
  - refines symptom features by embedding relational characteristics among symptoms to effectively estimate symptom levels

제안된 모델은 멀미에 대한 16개의 증상을 다룸

<br>

### Stimulus Symptom Context Guider

멀미가 발생하는 과정을 설명하는 neural mismatch theory 존재

expected sensory information이 actual sensory information과 match되지 않으면, neural mismatch가 발생해서 멀미로 이어짐

예외적인 동작에 대해 neural mismatch가 크다. (일상생활에서 자주 경험되지 않아서)

여기서의 **the sensory mismatch detector**는 mismatch features를 인코딩하도록 설계

sensory mismatch detector는 **visual expectation generator**를 포함

→ predicts the next frame I by taking previous frames $$ I_{t-N}, ... , I_{t-1} (N = 11) $$
$$
I_{t-N}, ... , I_{t-1} (N = 11)
$$
→ the viewports of VR content are used as input frames

→ contains ConvLSTMs and DeConvLSTMs with deconvolution

→ is pre-trained with videos that contains only non-exceptional motions and the high frame rate (예외적이지 않은 움직임, 높은 프레임 속도만 포함하는 비디오로 사전 훈련)

프레임 차이는 예외적인 움직임으로 사이버 멀미를 유도할 수 있는 VR의 경우 크다. 

**pixel-wise generation loss** is defined to train the generator.

Note that, the sensory mismatch detector is first <u>pre-trained</u> and the <u>weights are fixed</u>.

<br>

Based on the sensory mismatch detector, the stimulus context guider outputs **symptom group features** → represent nausea, oculomotor, and disorientation group factors in a context of stimulus

---

비디오 콘텐츠가 주어지면, 길이가 같은 세 개의 시간 섹션으로 분리

각각의 섹션에서, 무작위로 샘플된 content video sequence ($$ I_{t}, ... , I_{t+N-1} $$) and mismatch sequence ($$ M_{t}, ... , M_{t+N-1} $$) are used as inputs at training time → 무작위로 샘플링되어서 과적합 방지

the midst frames of each section are sampled at testing time

content → visual encoder

mismatch sequences → mismatch encoder

이 과정에서, 각 섹션의 VR content의 visual context와 visual mismatch는 3D-Conv layers로 인코딩.

3개의 섹션의 ouput features는 2D-conv 레이어를 가진 global context encoder로 연결되어 비디오의 overall context를 고려

마지막으로, fully connected layers가 평균값을 예측하기 위해 적용

these scores indicate the symptom group scores

training time → 각 컨텐츠에 대한 개인의 그룹 점수를 평균화하여 groundtruth mean score를 얻음

symptom group features는 VR 콘텐츠 자극에 의해 유도될 수 있는 증상에 대한 이전 context를 나타냄

<br>

### Physiological Symptom Guider

takes individual subject characteristics into consideration to extract symptom features

**takes EEG signal** acquired while watching VR content **to output symptom features**

EEG signal ..

→ baseline-drifting artifacts를 제거하기 위해 0.5Hz 컷오프 주파수의 high-pass filter 적용

→ muscular artifacts를 제거하기 위해 50Hz 컷오프 주파수의 low-pass filter 적용

<br>

C : EEG channer size

주파수 필터를 적용한 후, EEG signal의 spectrogram image를 Short-Time Fourier Transform (STFT)를 통해 얻어 주파수 특성 고려

Xbar는 EEG time-wise encoder로 들어감

→ 1D-Conv layer로 구성

→ Xbar의 temporal axis에 적용

→ therefore, does not mix the feature in frequency-wise



cybersickness를 예측하기 위한 중요 주파수 대역을 강조하기 위해 **frequency band attention encoder** 설계

→ 델타 / 세타 / 알파 / 베타 / 감마 대역에 해당하는 5개의 attention weights를 얻는 방법을 학습

각각의 밴드의 attention weight는 EEG feature map의 해당 주파수 영역에 위치해서 frequency band attention map을 형성

→ time-wise encoder로부터 EEG feature에 공간적으로 곱해진다. (spatially elementwise)

EEG feaure는 time과 frequency characteristics로 인코딩하기 위해서, 2D-Conv로 구성된 **time-freq-wise encoder**로 들어감 → 4개의 patch로 나뉨 (in terms of the temporal axis)

patch는 ConvLSTM에 시간 순서대로 입력됨

마지막으로 symptom levels는 fully connected layers에 의해 예측

<br>

The features used for each symptom prediction are considered as **symptom features** 

→ reflect physiological symptom characteristics related to cybersickness of individuals

<br>

### Symptom Relation Embedder

증상 간의 관계 특성을 인코딩하여 symptom features를 refine하기 위해 고안되었음

symptom group features와 symptom features를 수신

symptom characteristics와 stimulus context를 고려해서 unsupervised way로 증상 간의 관계를 학습

symptom features는 embedding relations를 통해 보완적으로 개선되므로 물리적 증상을 효과적으로 예측하는 데 사용할 수 있음

<br>

relational characteristics를 배우기 위해 graph formulation을 활용

